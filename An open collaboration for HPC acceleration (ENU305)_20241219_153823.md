# Summary of AWS re_Invent 2024 - An open collaboration for HPC acceleration (ENU305).txt

# AWS re:Invent 2024 - An open collaboration for HPC acceleration (ENU305)

## Summary

This session covered an open collaboration between AWS, energy companies (like Occidental and Shell), and technology partners (like Nvidia and S-Cube) to modernize and accelerate high-performance computing (HPC) workflows, specifically for the oil and gas industry and subsurface workloads.

### Main Points

- The collaboration aims to remove barriers to entry for HPC workloads on AWS, enabling collaboration across companies, solution providers, ISVs, and academia.
- The Energy HPC Orchestrator is a low-code/no-code application that allows customers to build HPC workflows by dragging and dropping components, including their own custom algorithms, third-party applications, and new ideas from academia or partners.
- It targets the right infrastructure (GPU, CPU, ARM) for the right application within HPC workflows, enabling customers to experiment, benchmark, and optimize for cost and performance.
- The Orchestrator decouples monolithic workflows into serverless, event-driven microservices, enabling scalability and integration of different algorithms and hardware.
- Key use cases demonstrated include seismic imaging (reverse time migration, full-wave inversion) and reservoir simulation, leveraging technologies like Nvidia's energy SDK and S-Cube's algorithms.
- The solution aims to integrate machine learning, generative AI, and large language models alongside traditional HPC workflows.
- Graviton instances and Nvidia's GPU capabilities (including the upcoming DGX Cloud on AWS) are leveraged for cost-effective and performant execution.

### Important Conclusions

- The collaboration enables smaller operators to access HPC capabilities previously limited to major players, fostering innovation and best-of-breed solutions.
- It allows customers to optimize for cost, performance, and specific geological formations by mixing and matching algorithms and hardware.
- The serverless, event-driven architecture decouples and scales complex HPC workflows, enabling rapid experimentation and integration of new technologies.
- Integrating AI/ML can further enhance and automate HPC workflows, from user interfaces to algorithm optimization and result interpretation.
- The solution aims to reduce the environmental impact of HPC through energy-efficient architectures like ARM and GPU acceleration.